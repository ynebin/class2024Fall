{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzYg+8IziNauJARd1YRtoi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ynebin/class2024Fall/blob/main/7_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "iWzWCwYppGU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "* External Packages\n",
        "\n",
        "```python\n",
        "!pip install gradio\n",
        "!pip install SpeechRecognition\n",
        "!pip install gtts\n",
        "```\n",
        "\n",
        "* Import Packages\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "from gtts import gTTS\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import gradio as gr\n",
        "import soundfile as sf\n",
        "import speech_recognition as sr\n",
        "```"
      ],
      "metadata": {
        "id": "ul06Ub9upVRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Calculator\n",
        "\n",
        "```python\n",
        "def add(first_num, second_num):\n",
        "  result = first_num + second_num\n",
        "  return f\"Answer is: {result}\"\n",
        "\n",
        "interface = gr.Interface(fn=add, inputs = [\"number\", \"number\"], outputs=\"text\")\n",
        "interface.launch()\n",
        "```"
      ],
      "metadata": {
        "id": "RMXj5bktpR3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill in the Blank\n",
        "\n",
        "```python\n",
        "fill_mask_model = pipeline(model=\"bert-base-uncased\")\n",
        "\n",
        "def fill_mask(text):\n",
        "    results = fill_mask_model(text)\n",
        "    results_list = [{ 'score': result['score'], 'token_str': result['token_str'], 'sequence': result['sequence']} for result in results]\n",
        "    return results_list\n",
        "\n",
        "interface = gr.Interface(fn=fill_mask, inputs=\"text\", outputs=\"json\")\n",
        "interface.launch()\n",
        "\n",
        "# The quick brown fox jumps over the deep [MASK].\n",
        "# In the center of the city, you can find busy [MASK].\n",
        "# The solar system consists of eight planets, including Earth and [MASK].\n",
        "```"
      ],
      "metadata": {
        "id": "zyXyS67mw9B_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Classification\n",
        "\n",
        "```python\n",
        "caption_generator = pipeline(model=\"ydshieh/vit-gpt2-coco-en\")\n",
        "\n",
        "def generate_caption(img):\n",
        "    pil_img = Image.fromarray(img)\n",
        "    result = caption_generator(pil_img)[0]['generated_text']\n",
        "    return result\n",
        "\n",
        "interface = gr.Interface(fn=generate_caption, inputs=\"image\", outputs=\"text\")\n",
        "interface.launch()\n",
        "```"
      ],
      "metadata": {
        "id": "Mf5hhGsFrMpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech-to-Text (STT)\n",
        "\n",
        "```python\n",
        "def stt(audio):\n",
        "    stt_model = sr.Recognizer()\n",
        "    s_rate, audio_data = audio\n",
        "    sf.write(\"stt_input.wav\", audio_data, s_rate)\n",
        "\n",
        "    with sr.AudioFile(\"stt_input.wav\") as source:\n",
        "        audio_recorded = stt_model.record(source)\n",
        "        text = stt_model.recognize_google(audio_recorded)\n",
        "    return text\n",
        "\n",
        "interface = gr.Interface(fn=stt, inputs=\"microphone\", outputs=\"text\")\n",
        "interface.launch()\n",
        "```"
      ],
      "metadata": {
        "id": "B_h-8IHC0Ie_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text-to-Speech (TTS)\n",
        "\n",
        "```python\n",
        "def tts(text):\n",
        "  tts_model = gTTS(text)\n",
        "  tts_model.save(\"tts_output.wav\")\n",
        "  return \"tts_output.wav\"\n",
        "\n",
        "interface = gr.Interface(fn=tts, inputs=\"text\", outputs=\"audio\")\n",
        "interface.launch()\n",
        "```"
      ],
      "metadata": {
        "id": "QuCGVeIw07pO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voice Chatbot\n",
        "\n",
        "```python\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "chat_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "def stt(audio):\n",
        "  stt_model = sr.Recognizer()\n",
        "  s_rate, audio_data = audio\n",
        "  sf.write(\"stt_input.wav\", audio_data, s_rate)\n",
        "\n",
        "  with sr.AudioFile(\"stt_input.wav\") as source:\n",
        "    audio_recorded = stt_model.record(source)\n",
        "    text = stt_model.recognize_google(audio_recorded)\n",
        "  return text\n",
        "\n",
        "def tts(text):\n",
        "  tts_model = gTTS(text)\n",
        "  tts_model.save(\"tts_output.wav\")\n",
        "  return \"tts_output.wav\"\n",
        "\n",
        "# No chat history\n",
        "def chatbot(text):\n",
        "  input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors=\"pt\")\n",
        "  output_ids = chat_model.generate(input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "  output = tokenizer.decode(output_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "  return output\n",
        "\n",
        "def voice_chatbot(audio):\n",
        "  user_text = stt(audio)\n",
        "  chatbot_text = chatbot(user_text)\n",
        "  speech_file = tts(chatbot_text)\n",
        "  return user_text, chatbot_text, speech_file\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=voice_chatbot,\n",
        "    inputs=\"microphone\",\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"User Text\"),\n",
        "        gr.Textbox(label=\"Chatbot Response\"),\n",
        "        gr.Audio(label=\"Chatbot Audio\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "interface.launch()\n",
        "```"
      ],
      "metadata": {
        "id": "Aimmzztm1yt7"
      }
    }
  ]
}